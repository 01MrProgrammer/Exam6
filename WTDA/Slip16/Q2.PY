import re
import nltk
from nltk.tokenize import sent_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Function to preprocess the text
def preprocess_text(text):
    # Remove special characters and digits
    processed_text = re.sub(r'[^a-zA-Z\s]', '', text)
    return processed_text

# Function to generate summary using extractive summarization
def generate_summary(text, num_sentences=2):
    # Preprocess the text
    processed_text = preprocess_text(text)
    
    # Tokenize the text into sentences
    sentences = sent_tokenize(processed_text)
    
    # Create TF-IDF vectorizer
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(sentences)
    
    # Calculate cosine similarity matrix
    similarity_matrix = cosine_similarity(X, X)
    
    # Calculate sentence importance scores
    sentence_scores = similarity_matrix.sum(axis=1)
    
    # Get indices of top-ranking sentences
    top_sentences_indices = sentence_scores.argsort()[-num_sentences:][::-1]
    
    # Generate summary
    summary = [sentences[i] for i in top_sentences_indices]
    return ' '.join(summary)

# Example text paragraph
text_paragraph = """
Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.

NLP techniques are used in a wide range of applications, including machine translation, speech recognition, text summarization, sentiment analysis, and more. In recent years, there have been significant advancements in NLP thanks to deep learning models like transformers.

Extractive summarization is a technique in NLP where the summary is generated by selecting and combining important sentences directly from the input text. It does not involve any rewriting or paraphrasing of sentences. Instead, it identifies the most important sentences based on various criteria such as word frequency, sentence length, or semantic similarity.

In this example, we'll demonstrate how to preprocess a text paragraph and generate a summary using extractive summarization techniques.
"""

# Generate summary
summary = generate_summary(text_paragraph)
print("Summary:")
print(summary)
